{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6799995f",
   "metadata": {},
   "source": [
    "# Machine Learning Midterm - Online Transaction\n",
    "\n",
    "## Rayhan Diff-1103220039"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70863138",
   "metadata": {},
   "source": [
    "## Import Library\n",
    "\n",
    "import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7aef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import gc \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1be81",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a72712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Shape Train: (590540, 394)\n",
      "Shape Test: (506691, 393)\n",
      "Encoding categorical columns...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv('train_transaction.csv')\n",
    "test_df = pd.read_csv('test_transaction.csv')\n",
    "\n",
    "print(f\"Shape Train: {train_df.shape}\")\n",
    "print(f\"Shape Test: {test_df.shape}\")\n",
    "\n",
    "# 2. temporary combine for consistent preprocessing\n",
    "test_df['isFraud'] = -1\n",
    "all_data = pd.concat([train_df, test_df], axis=0, sort=False).reset_index(drop=True)\n",
    "\n",
    "# 3. Handling Missing Values & Categorical Encoding\n",
    "\n",
    "# Identified column\n",
    "cat_cols = all_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Encoding categorical columns...\")\n",
    "for col in cat_cols:\n",
    "    all_data[col] = all_data[col].fillna('Unknown')\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    all_data[col] = le.fit_transform(all_data[col].astype(str))\n",
    "\n",
    "train_df = all_data[all_data['isFraud'] != -1].copy()\n",
    "test_df = all_data[all_data['isFraud'] == -1].copy()\n",
    "\n",
    "test_df = test_df.drop('isFraud', axis=1)\n",
    "\n",
    "del all_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b00093",
   "metadata": {},
   "source": [
    "## Feature Engineering & Class Imbalance\n",
    "In this section, the data imbalance problem is addressed. When the number of fraud cases is extremely small, the model tends to predict “Not Fraud” repeatedly. This issue is handled using specific parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677e535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Imbalance Ratio: 27.58\n"
     ]
    }
   ],
   "source": [
    "# Defining the Features (X) and the Target (y)\n",
    "X = train_df.drop(['isFraud', 'TransactionID'], axis=1)\n",
    "y = train_df['isFraud']\n",
    "\n",
    "X_test_final = test_df.drop(['TransactionID'], axis=1) # For final submission\n",
    "\n",
    "# Splitting Data for Local Validation (80% Train, 20% Validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Calculating Scale Pos Weight for Class Imbalance\n",
    "# Formula: number_of_negatives / number_of_positives\n",
    "ratio = float(np.sum(y == 0)) / np.sum(y == 1)\n",
    "print(f\"Class Imbalance Ratio: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a1958",
   "metadata": {},
   "source": [
    "## Training model XGBoost\n",
    "The AUC (Area Under the Curve) metric is used because predicting probabilities rather than merely assigning 0 or 1 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e869be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Training...\n",
      "[0]\tvalidation_0-auc:0.86305\n",
      "[50]\tvalidation_0-auc:0.92255\n",
      "[100]\tvalidation_0-auc:0.93718\n",
      "[150]\tvalidation_0-auc:0.94829\n",
      "[200]\tvalidation_0-auc:0.95410\n",
      "[250]\tvalidation_0-auc:0.95799\n",
      "[300]\tvalidation_0-auc:0.96062\n",
      "[350]\tvalidation_0-auc:0.96256\n",
      "[400]\tvalidation_0-auc:0.96430\n",
      "[450]\tvalidation_0-auc:0.96547\n",
      "[499]\tvalidation_0-auc:0.96645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=&#x27;cuda&#x27;, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=&#x27;cuda&#x27;, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device='cuda', early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=9,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost configuration\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=500,           # Number of trees\n",
    "    max_depth=9,                # Tree depth\n",
    "    learning_rate=0.05,         # Learning rate\n",
    "    subsample=0.9,              # Prevent overfitting\n",
    "    colsample_bytree=0.9,       # Prevent overfitting\n",
    "    missing=np.nan,             # Automatically handle NaN values\n",
    "    eval_metric='auc',          # Main evaluation metric\n",
    "    n_jobs=-1,                  # Use all CPU cores\n",
    "    scale_pos_weight=ratio,     # KEY FOR IMBALANCED DATA\n",
    "    tree_method='hist',     # Use GPU for training\n",
    "    device='cuda',    \n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50,   # Stop if score does not improve for 50 rounds\n",
    ")\n",
    "\n",
    "print(\"Starting Model Training...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a34bc8d",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12da218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [14:10:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation ROC-AUC Score: 0.9664\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98    113975\n",
      "           1       0.48      0.82      0.61      4133\n",
      "\n",
      "    accuracy                           0.96    118108\n",
      "   macro avg       0.74      0.89      0.79    118108\n",
      "weighted avg       0.98      0.96      0.97    118108\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "    feature  importance\n",
      "310    V258    0.156976\n",
      "122     V70    0.078288\n",
      "270    V218    0.065714\n",
      "143     V91    0.051541\n",
      "253    V201    0.036998\n",
      "346    V294    0.033836\n",
      "28      C14    0.010792\n",
      "215    V163    0.010411\n",
      "22       C8    0.009577\n",
      "194    V142    0.006850\n"
     ]
    }
   ],
   "source": [
    "# Probability Prediction (for AUC calculation)\n",
    "y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Label Prediction (0 or 1 with default threshold 0.5)\n",
    "y_pred_label = model.predict(X_val)\n",
    "\n",
    "# 1. ROC-AUC Score (Main Metric)\n",
    "auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "print(f\"\\nValidation ROC-AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# 2. Classification Report (To see Precision & Recall)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_label))\n",
    "\n",
    "# 3. Feature Importance (Which features are most influential?)\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aaf45b",
   "metadata": {},
   "source": [
    "## Test Set Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28cb93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "SAMPLE SUBMISSION PREVIEW\n",
      "========================================\n",
      "        TransactionID   isFraud\n",
      "590540        3663549  0.003068\n",
      "590541        3663550  0.010426\n",
      "590542        3663551  0.004724\n",
      "590543        3663552  0.013365\n",
      "590544        3663553  0.002487\n",
      "590545        3663554  0.038541\n",
      "590546        3663555  0.025501\n",
      "590547        3663556  0.087754\n",
      "590548        3663557  0.000404\n",
      "590549        3663558  0.082110\n",
      "\n",
      "========================================\n",
      "PREDICTION STATISTICS\n",
      "========================================\n",
      "count    506691.000000\n",
      "mean          0.095619\n",
      "std           0.171669\n",
      "min           0.000007\n",
      "25%           0.008409\n",
      "50%           0.030644\n",
      "75%           0.097773\n",
      "max           0.999897\n",
      "Name: isFraud, dtype: float64\n",
      "\n",
      "Number of transactions predicted as High Risk Fraud (>50%): 20779 out of 506691 data.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Final Prediction on Test Set\n",
    "test_probs = model.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"SAMPLE SUBMISSION PREVIEW\")\n",
    "print(\"=\"*40)\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"PREDICTION STATISTICS\")\n",
    "print(\"=\"*40)\n",
    "# Displaying statistics (mean, min, max) to ensure the predictions are valid\n",
    "print(submission['isFraud'].describe())\n",
    "\n",
    "# Check how many are predicted to have a high risk of Fraud (> 50%)\n",
    "high_risk_count = (submission['isFraud'] > 0.5).sum()\n",
    "print(f\"\\nNumber of transactions predicted as High Risk Fraud (>50%): {high_risk_count} out of {len(submission)} data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86976e48",
   "metadata": {},
   "source": [
    "# Conclusion & Analysis\n",
    "Based on the development of the *end-to-end* Machine Learning pipeline using XGBoost for Fraud Detection, here are the key takeaways and analysis derived from the model performance:\n",
    "\n",
    "## A. Model Performance\n",
    "- **Handling Class Imbalance**  \n",
    "  The model successfully addressed the massive class imbalance (Ratio ~1:27) by using the `scale_pos_weight` parameter and a histogram-based optimization (`tree_method='hist'`) on GPU.\n",
    "\n",
    "- **Excellent Discriminative Ability**  \n",
    "  The model achieved a ROC-AUC Score of **0.9664** on the validation set. This indicates that the model has a *96.6%* probability of correctly distinguishing between fraudulent and normal transactions.\n",
    "\n",
    "- **High Recall (Sensitivity)**  \n",
    "  The Classification Report shows a Recall of **0.82** for the Fraud class (1). This is the most important metric in fraud detection, meaning the model successfully captures *82%* of all actual fraud cases.\n",
    "\n",
    "- **Precision Trade-off**  \n",
    "  The Precision for the Fraud class is **0.48**, indicating a trade-off with false positives (around 52% of predicted frauds might actually be legitimate). In real-world scenarios, this is acceptable since it is safer to flag transactions for review than to let fraud slip through.\n",
    "\n",
    "## B. Feature Importance Analysis\n",
    "The XGBoost model automatically identified the most significant signals in the dataset. The top features contributing to fraud predictions are:\n",
    "\n",
    "- **V258** (Importance: ~0.157) — The dominant feature  \n",
    "- **V70** (Importance: ~0.078)  \n",
    "- **V218** (Importance: ~0.065)  \n",
    "\n",
    "These findings suggest that variables related to transaction frequency or historical behavior (anonymized as *V-features*) play a more influential role than direct identity attributes in this model.\n",
    "\n",
    "## C. Test Set Prediction Profile\n",
    "On the unlabeled test set (`test_transaction.csv`), the model demonstrates a realistic prediction distribution:\n",
    "\n",
    "- **Mean Fraud Probability:** 9.5%  \n",
    "- **High-Risk Flags (> 50% probability):** 20,779 transactions out of 506,691  \n",
    "\n",
    "This volume is manageable for prioritized manual review or the implementation of secondary authentication layers in a production environment.\n",
    "\n",
    "## D. Final Verdict\n",
    "The XGBoost model proves to be *highly effective* and *efficient* for this high-dimensional, imbalanced tabular dataset. It achieves a near *state-of-the-art* AUC score with minimal feature engineering, reinforcing the effectiveness of gradient boosting trees for financial fraud detection.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
